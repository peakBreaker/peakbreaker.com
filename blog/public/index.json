[
{
	"uri": "https://blog.peakbreaker.com/about/",
	"title": "About Me",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "Trying to figure things out",
	"content": "As a human being, I am full of biases. I find myself often wrong, and oftentimes worrying about things out of my reach. The older I get, the more I am reaching the conclusion that I know very little about this world - and I am a very lucky person indeed if I can really be sure of anything.\nMy story I started out from a middleclass background in Norwegian society - though a bit outside the major urban and mainstream culture - from a small place called \"Hole kommune\". From my childhool I found myself mesmerized over technology - bugging my parents in the middle of the night because I was disassembling radios, or taking apart their phone. Naturally I would find myself in university studying mechatronics - the field of mechanics and electronics working together to create cool machines. I also had fun being in the student organization such as the student bar and student parliament. During my studies, I found my passions drifting towards taming the complexity of software and the entrepreneuiral scene and the machinery of policy. Fresh out of university I tried getting elected as major of my home municipality and I crowdfunded a zero waste grocery with thse nice people.\nSomehow I find myself later programming C and the telecommunications codebase of a startup in Bergen, Norway (yes, its the city with all the rain). The goal is to build an IoT product one can put in boats to make the boat smart - Possibly saving lives along with improving efficiency #smartinfrastructure\nI later carry out the development of embedded C drivers for their product aswell. To test the devices - I collect data and build datasets for the product, only to push myself towards the field of data.\nThese days I find myself in Amedia Utvikling AS, being brought to the company as a Data Engineer - where I really get to challenge myself in how to create technology to handle big data. I even met Jesse Anderson on an OReilly conference (Yes, I was a bit nervous - huge fan)\n"
},
{
	"uri": "https://blog.peakbreaker.com/",
	"title": "",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/categories/",
	"title": "Categories",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/categories/data/",
	"title": "data",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/post/2019-03-05-dataframe-funtimes/",
	"title": "More data manipulation with pandas",
	"tags": ["pandas,", "python"],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Data Exploration Working with data is a lot of fun. In this day and age, there is a lot of data,\nbut a lack of data stories. Exploring data is about uncovering the stories\nthat the data may hold - whether it is anomalies or powerful insights.\nBeyond the basics My first post on working\nwith data using pandas goes into the basics of cleaning data and some core\nutilities, I would recommend starting there. In this post I will be exploring\nsome further tools to manipulating data and uncovering data stories.\nData insight Say we start out with a dataset provided by The Guardian on olympic medals won throughout the years.\nn [1]: medals.head() ... Out[1]: City Edition Sport Discipline Athlete NOC Gender Event Event_gender Medal 0 Athens 1896 Aquatics Swimming HAJOS, Alfred HUN Men 100m freestyle M Gold 1 Athens 1896 Aquatics Swimming HERSCHMANN, Otto AUT Men 100m freestyle M Silver 2 Athens 1896 Aquatics Swimming DRIVAS, Dimitrios GRE Men 100m freestyle for sailors M Bronze 3 Athens 1896 Aquatics Swimming MALOKINIS, Ioannis GRE Men 100m freestyle for sailors M Gold 4 Athens 1896 Aquatics Swimming CHASAPIS, Spiridon GRE Men 100m freestyle for sailors M Silver Nice utils These are nice pandas utils that should be quite straight forward. Nice to use\n nunique  1 2  grouped = medals.groupby(\u0026#39;NOC\u0026#39;) # Group by country grouped[\u0026#39;Sport\u0026#39;].nunique().sort_values(ascending=False) # Gives num unique sports per country    isin  1 2  is_usa_urs = medals[\u0026#39;NOC\u0026#39;].isin([\u0026#39;USA\u0026#39;, \u0026#39;URS\u0026#39;]) # Get boolean series medals.loc[is_usa_urs] # Get all rows won by either usa or urs    idxmax \u0026amp; idxmin  1 2 3 4 5 6 7 8 9  # Create the pivot table: medals_won_by_country medals_won_by_country = medals.pivot_table(index=\u0026#39;Edition\u0026#39;, columns=\u0026#39;NOC\u0026#39;, values=\u0026#39;Athlete\u0026#39;, aggfunc=\u0026#39;count\u0026#39;) # Slice medals_won_by_country: cold_war_usa_urs_medals cold_war_usa_urs_medals = medals_won_by_country.loc[1952:1988, [\u0026#39;USA\u0026#39;,\u0026#39;URS\u0026#39;]] # Create most_medals  most_medals = cold_war_usa_urs_medals.idxmax(axis=\u0026#39;columns\u0026#39;) # Who won the most medals between ussa and urs during the cold war? print(most_medals.value_counts())   value_counts We can get the number of medals won per country by using\nvalue_counts:\n1 2 3 4 5  # Count the number of medals won by each country: medal_counts medal_counts = country_names.value_counts() # Print top 15 countries ranked by medals print(medal_counts.head())   outputs:\n USA 4335 URS 2049 GBR 1594 FRA 1314 ITA 1228 pivot_table We can count the values by type using\npivot_table\n1 2 3 4 5 6 7 8 9  counted = medals.pivot_table( index=\u0026#39;NOC\u0026#39;, # Country as index values=\u0026#39;Athlete\u0026#39;, # Values we will run the aggfunc on columns=\u0026#39;Medals\u0026#39;, # Columns aggfunc=\u0026#39;count\u0026#39; # How we aggregate the values ) counted[\u0026#39;totals\u0026#39;] = counted.sum(axis=\u0026#39;columns\u0026#39;) counted.sort_values(\u0026#39;totals\u0026#39;, ascending=False)   grouping Grouping is taking common values and creating sets of dataframes underneath.\nThats how I think about it anyway. Grouping by multiple columns will give\na multi-index df.\n1  medals.groupby([\u0026#39;Event_gender\u0026#39;, \u0026#39;Gender\u0026#39;])   outputs:\n City Edition Sport Discipline Athlete NOC Event Medal Event_gender Gender M Men 20067 20067 20067 20067 20067 20067 20067 20067 W Men 1 1 1 1 1 1 1 1 Women 7277 7277 7277 7277 7277 7277 7277 7277 X Men 1653 1653 1653 1653 1653 1653 1653 1653 Women 218 218 218 218 218 218 218 218 boolean selection Using boolean operations, we can select values from dfs very nicely:\n1  medals[(medals[\u0026#39;Gender\u0026#39;] == \u0026#39;Men\u0026#39;) \u0026amp; (medals[\u0026#39;Event_gender\u0026#39;] == \u0026#39;W\u0026#39;)]   This returns one row?\nStack/unstack Ehm, Todo.\nFinally some visualization Attractive graphs are nice. Lets make some. Area plots and violin plots are my\nfavorite.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # Redefine \u0026#39;Medal\u0026#39; as an ordered categorical medals.Medal = pd.Categorical(values=medals[\u0026#39;Medal\u0026#39;], categories=[\u0026#39;Bronze\u0026#39;, \u0026#39;Silver\u0026#39;, \u0026#39;Gold\u0026#39;], ordered=True) # Create the DataFrame: usa usa = medals[medals.NOC == \u0026#39;USA\u0026#39;] # Group usa by \u0026#39;Edition\u0026#39;, \u0026#39;Medal\u0026#39;, and \u0026#39;Athlete\u0026#39; usa_medals_by_year = usa.groupby([\u0026#39;Edition\u0026#39;, \u0026#39;Medal\u0026#39;])[\u0026#39;Athlete\u0026#39;].count() # Reshape usa_medals_by_year by unstacking usa_medals_by_year = usa_medals_by_year.unstack(level=\u0026#39;Medal\u0026#39;) # Create an area plot of usa_medals_by_year usa_medals_by_year.plot.area() plt.show()   "
},
{
	"uri": "https://blog.peakbreaker.com/tags/pandas/",
	"title": "pandas,",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/post/",
	"title": "Posts",
	"tags": ["index"],
	"categories": [],
	"series": [],
	"description": "Post page",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/python/",
	"title": "python",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/",
	"title": "Tags",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/crypto/",
	"title": "crypto",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/gpg/",
	"title": "gpg",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/security/",
	"title": "security",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/categories/sysadmin/",
	"title": "SysAdmin",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/post/2019-02-27-get-yourself-verified/",
	"title": "Welcome to the VIP",
	"tags": ["security", "crypto", "gpg"],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Being Verified Computer security in essence boils down to two things:\n Authentication : How can we prove who you are? Authorization : What access do you have?  Implementing secure systems often comes down to good habits. This\nis one topic where the broken window theory tends to show its symptomps.\nMeaning small hacks, lazinesses and lowering of standards tend to propagate and\neventually cause the whole system to become and unmaintainable mess.\nI absolutely recommend reading the pragmatic programmer for more on this.\nGood crypto habits is a good thing. If you are to be trusted as an\nadministrator of a system, then you should have good habits on crypto, and take\ncomputer security seriously.\nSigning commits with GPG Gnu Privacy Guard or GPG is the underlying open source clockwork behind a lot\nof crypto in the UNIX ecosystem. So lets use it to sign our commits. Heres the\nbreakdown.\nFirst lets create the key pair\n1 2 3  gpg --gen-key gpg --list-secret-keys --keyid-format LONG # find the \u0026lt;key\u0026gt; gpg --armor --export \u0026lt;key\u0026gt; # Public key for github   And configure git and git(Hub/Lab)\n1 2  git config --global user.signinkey \u0026lt;key\u0026gt; git config --global commit.gpgsign true   The public key provided in the line of the first stage should be put in your\naccount on github/gitlab/whatever\nCongrats, you should now be verified!\n"
},
{
	"uri": "https://blog.peakbreaker.com/post/2018-11-22-data-cleaning-with-pandas/",
	"title": "Data Cleaning with pandas",
	"tags": ["pandas", "python"],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Clean data Pandas is a data library. I dont actually mean those cute bears.\nThis post is based on a pull from my personal notes when learning to work with\ndata in python with pandas (So it might not be perfect, but hey - Im trying).\nThese are some of the essentials tools/skills I picked up about cleaning data.\nData scientists actually spend the majority of their time wrangling and cleaning\ndata, as it is a time consuming and complex process - kind of a grind. It\nis, however, a very essential part of working with data, which is hard to\navoid - and because of this, its worth looking into getting efficient at it.\nThe conventions in pandas is that pandas is imported as pd and dataframes are\ncalled df. Im sticking to that convention in my notes.\nPandas Core utilities These are some of the essential functions for exploring data with pandas\nExtracting some samples: 1 2  df.head() # Gets first 5 rows df.tail() # Gets last 5 rows   Getting some df metadata: 1 2 3 4 5  df.info() # Gets essential info on dataframe df.dtypes # Datatypes df.columns # get/set df.describe() # Some statistical values on the df df[\u0026#39;column\u0026#39;].value_counts() # counts of unique values on the column (Series method)   Some quick visualization 1 2  df.column.plot(\u0026#39;hist\u0026#39;) # For histogram df.plot(kind=\u0026#39;scatter\u0026#39;, x=\u0026#39;col\u0026#39;, y=\u0026#39;col\u0026#39;) # Scatter   may need to import matplotlib.pyplot as plt and run plt.show() below\nData cleaning Normalized data: These are the allmighty laws of normalized data\n Rows form observations Columns form variables Datasets form observational units  Melting and pivoting data: Meltings turns columns into rows\n1 2  pd.melt(frame=df, id_vars=\u0026#39;fixed_column\u0026#39;, value_vars=[\u0026#39;columns\u0026#39;, \u0026#39;to\u0026#39;, \u0026#39;melt\u0026#39;], var_name=\u0026#39;variable col name\u0026#39;, value_name=\u0026#39;value column name\u0026#39;)   This will reslt in the fixed_column column to be untouched, just broadcasted\ndown, while the value_vars columns will be turned into a variable and value\nname column\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026gt;\u0026gt;\u0026gt; df A B C 0 a 1 2 1 b 3 4 2 c 5 6 \u0026gt;\u0026gt;\u0026gt; pd.melt(df, id_vars=[\u0026#39;A\u0026#39;], value_vars=[\u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;], ... var_name=\u0026#39;myVarname\u0026#39;, value_name=\u0026#39;myValname\u0026#39;) A myVarname myValname 0 a B 1 1 b B 3 2 c B 5 3 a C 2 4 b C 4 5 c C 6   Pivoting takes unique vals from columns and alter the dataset by creating new\ncolumns:\n1  df.pivot(index=\u0026#39;foo\u0026#39;, columns=\u0026#39;bar\u0026#39;, values=\u0026#39;baz\u0026#39;)   This will result in the \u0026lsquo;foo\u0026rsquo; column becoming the new index, the \u0026lsquo;columns\u0026rsquo;\ncolumn becoming the columns and \u0026lsquo;baz\u0026rsquo; column becoming the actual values of the\ndataframe.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026gt;\u0026gt;\u0026gt; df foo bar baz 0 one A 1 1 one B 2 2 one C 3 3 two A 4 4 two B 5 5 two C 6 \u0026gt;\u0026gt;\u0026gt; df.pivot(index=\u0026#39;foo\u0026#39;, columns=\u0026#39;bar\u0026#39;, values=\u0026#39;baz\u0026#39;) bar A B C foo one 1 2 3 two 4 5 6   Melting and pivoting can be very useful when cleaning data and making it normalized (see criteria on\nnormalized data above)\nAs we also can see, melting and pivoting are opposites\nData Combining: Grouping data: Pandas allows us to group data together:\n1  df.groupby(\u0026#39;column\u0026#39;)  \nThis will make pandas group the data by the unique values. Basically it looks\nthrough the column and groups together the indexes of the different values. It\nreturns a special group object which we can iterate on and get attributes on to\nlook at the different groups. Each group in the grouped object is basically\na dataframe for the given group.\nTutorialspoint\nhas a tutorial on this that I found very useful.\nGlobbing: Globbing is useful when retreiving files in a directory, see sample use below:\n1  glob.glob(./*.csv) # gets all csv files in current dir  \nConcatenating data: Basically, concatenating frames together just glues together multiple frames.\n1  pd.concat([df1, df2, ...][, ignore_index=True, axis=1 ])  \npandas docs\nhas a nice guide on this.\nMerging data: Well mergining is merging. Pandas looks at the on keys and\n1  pd.merge(left=dfl, right=dfr, [left_on=\u0026#39;left column\u0026#39;, right_on=\u0026#39;right column\u0026#39;, on=\u0026#39;shared column\u0026#39;])  \nprovide either on=.. if same column name or left_on/right_on if differnt name\ncolumns\nReturned will be the merged dataset. So for example with a users df with id\ncolumn merged with visit df with user_id column will give us a df with visits\nand user info provided, which is nice.\nCleaning data: Datatype Altering: The more I learn about programming and CS, the more I learn that there are\nbasically two important things: datatypes and algorithms. Lets work with some\npandas datatype altering.\n1 2 3 4  # turn a column of strings to numeric column df[\u0026#39;numbers_as_strings\u0026#39;] = pd.to_numeric(df[\u0026#39;numbers_as_strings\u0026#39;]) # turn a column of categories (feks: [\u0026#39;M\u0026#39;, \u0026#39;F\u0026#39;]) to categories df[\u0026#39;col\u0026#39;].astype(\u0026#39;category\u0026#39;)  \nThese are very handy, and good clean data should have appropriate datatypes.\nIf all columns are object the df is going to have low performance and be more\ndifficult to work with.\nRegex: Regexes are hugely useful when working with strings. Im not going to cover here\nhow regexes work or how Series.str works, just some basic use of these on a df.\n1 2 3 4 5 6 7 8 9  # Compiling a basic regex pattern = re.compile(\u0026#39;\\d+\u0026#39;) # matches 1 or many numbers pattern.match(\u0026#39;w0rd\u0026#39;) # False pattern.match(\u0026#39;123\u0026#39;) # True # Using on df df[\u0026#39;column\u0026#39;].str.replace(\u0026#39;\\d+\u0026#39;, \u0026#39;replacement\u0026#39;, regex=True) df[\u0026#39;column\u0026#39;].str.extract(\u0026#39;\\d+\u0026#39;, expand=True) # Pulls out the first full number df[df[\u0026#39;col\u0026#39;].str.contains(\u0026#39;\\d+\u0026#39;, regex=True)] # Get rows w/ number in \u0026#39;col\u0026#39;   Functions to clean data: One can write python functions or lambdas for doing operations on the data.\nThis isnt just important when cleaning, its a general important data utility.\n1 2 3 4 5  def myfunc(row): return np.sum(row) def mycolfunc(value): return value + 1   And applying the function to the datasets:\n1 2  df[\u0026#39;myfunc_results\u0026#39;] = df.apply(myfunc, axis=1) # Run row-wise function df[\u0026#39;numplus1\u0026#39;] = df[\u0026#39;num\u0026#39;].apply(myfunc) # run func on every val in \u0026#39;num\u0026#39; column   Basically what to remember is that running axis=1 causes the function to handle\nrows, and axis=0 (default) runs the function cell-wise (even when not\nspecifying columns to run on)\nDropping duplicates, filling missed: Some handy utils when you clean data.\n1 2 3  df.drop_duplicates() # Only unique rows remain df.dropna() # Rows with NaNs are removed df[\u0026#39;col\u0026#39;].fillna(value) # NaNs are replaces with value  \nTesting: To ensure that the datacleaning was successful, it can be very helpful to set\nup some tests at the end of the program. Below are some useful samples.\n1 2 3 4 5 6  # Test that the data is clean assert(condition) # Checking if no values in df is NaN pd.notnull(df).all().all() # Checking that all df values are larger or equal to zero (df \u0026gt;= 0).all().all()  \n"
},
{
	"uri": "https://blog.peakbreaker.com/tags/cloud/",
	"title": "cloud",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/categories/docs/",
	"title": "Docs",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/documentation/",
	"title": "Documentation",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/gh-pages/",
	"title": "gh-pages",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/heroku/",
	"title": "heroku",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/oauth/",
	"title": "oauth",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/readthedocs/",
	"title": "readthedocs",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/rtfd/",
	"title": "rtfd",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/post/2018-11-13-scalable-docs/",
	"title": "Scalable Documentation",
	"tags": ["Sphinx", "Python", "Documentation", "gh-pages", "oauth", "readthedocs", "rtfd", "heroku", "cloud"],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Documentation In this entry, I am happy to be writing about something I have feelings\nfor and about. Documentation is one of those core needs in the maslow pyramid\nof technology, yet far too often overlooked.\nIt sounds easy, right? Just write some documents on what youre doing. Wrong,\nthat attitude does not scale. Unmaintained documentation is worse than no\ndocumentation, and documentation accumulates the same technical dept as code,\nthus it should be treated with atleast as much love.\nIn addition documentation means so many different things, so in order to have\nany communication on this subject, we need to specify what documentation even\nmeans.\nWhat is documentation Documentation comes from the english word \u0026ldquo;Document\u0026rdquo; which means\na \u0026ldquo;representation of thought\u0026rdquo;. Man, thats deep.\nWhen you write, you write to different audiences. In my case here, Im writing to\nsomeone called \u0026ldquo;no one\u0026rdquo; (cry). You are also writing for different purposes,\nIn my case here, Im writing because I have a strange affiliation with\ndocumentation.\nTL;DR on this chapter: Documentation can roughly be divided in two, Process\ndocumentation for the devs, engineers and whatnot which needs some level of\ntechnical competence to read, and User documentation which is for those pesky users\nwho doesnt necessarily have years of experience with the technology you spend\nyour life building.\nLets go through some different types of docuementation for some examples:\nCode as Documentation: When you craft code, your code should be clear enough\nto self document what it is doing. Comments in code should tell you Why the\ncode is doing whatever it is doing. Docstrings, those comments at the top of\nfiles, classes, functions and whatever else, provide an idea of usage. We'll\nget back to docstrings.\nREADME: Provides instructions on running your project and setting up\na devenv. Pretty essential to any project.\nAPI Docs: Guide and reference for how to use your API. Should absolutely be\nprovided if you want people to use your technology.\nStyle guides: Document which detemines the style guide and conventions for\nwhatever. For example, should variable names follow PascalCase, camelCase or\nunder_scores? Well theres a lot more to this, but it sets the conventions for\nthe technology development, so we can all follow the same standards, which is\nvery nice.\nRequirements \u0026amp; design documents: Bridge between devs and stakeholders,\noutlines the architecture and overviews the software.\nWiki/Guides: Explains concepts for the technology. For example, I used\na ringbuffer like datastructure once and created a wiki entry to explain the\nconceptual level of how it works. May also provide mathematics on how something\nworks, which is great as its a very efficient way of expressing concepts.\nUser manuals: How a user should use your product, but often also loved by\nthe SysAdmin.\nSo documenation come in very many flavors, and have many different use-cases.\nThere are some additional ones, such as QA documents, but those should almost\nhave a own blogpost for themselves.\nChallanges with documentation With such complexity and so many different forms of documentation, there are\nplenty of challenges with writing documentation:\n It is timeconsuming It can be(come) misleading It can become unsynced with the source (if you change the code it documents,\nbut not the documentation) It becomes an ad-hoc operation  So many engineers and developers hate it, or dont do it all. It is often joked\nthat omitting documentation gives work security, because when youre the only\none who knows the technology, then you cant be fired. hehe.\nHEHEHEHE.\nWhy document So with all these challenges, why bother spending time and resources to write\ngood documentation? Why even write documentation at all? Well:\n 6 months from now, you're gonna thanks yourself because you dont remember the\ndetails of the technology you made You want to create value (thats why youre working with tech, right?) and be\nuseful for the people around you You want people to use your technology (it makes your technology more\nvaluable, which is good for you) It structures your thoughts and improved your technology You cant scale without Software Engineering and documentation is a part of SE  Okay great, but again writing bad and misleading documenation is worse than no\ndocumentation. So we must apply systems and tools to automate and scale the way\nwe do documentation, so that we can be more efficient and effective at our\ntechnical writing skills. Thus Im going to introduce a toolchain for docs\nbelow, and we'll get started with some proper docs. Sound good? Great!\nScalable documentation toolchain Lets implement a documentation stack for automating our documentation workflow!\nRound 1: Sphinx with Readthedocs Sphinx is a rather mature documentation tool, being heavily used in the python\ncommunity, and written almost entirely in python. It is the tool used for\ndocumenting a large number of open source projects, for example the:\n Linux Kernel, Python itself, Blender And many more  First off on creating a scalable documentation stack with sphinx is to get\nsphinx up and running. In addition I will host the test project on readthedocs,\nfor demo purposes and because its very quick and easy.\nPrereq  python with virtualenv and pip git virtualenv venv \u0026amp;\u0026amp; source venv/bin/activate pip install sphinx  Setting up sphinx Key points:\n Sphinx is based on the rst text format, but can be extended to use markdown Sphinx provides a nice wizard and some utitiles for building docs with make\nright off the bat  A good guide is already provided in the readthedocs docs. TL;DR we do the following\n$ mkdir docs \u0026amp;\u0026amp; cd docs $ sphinx-quickstart # and stick to defaults $ make html $ $BROWSER _builds/html/index.html If the above commands succeeded, you should have very basic docs in your browser\nnow. Sphinx uses rst and many nifty things to bring home good documentation,\nand you will use the web and sphinx doc when\ndoing your actual documentation.\nHowever there is a few key skills which is important in order to write scalable\ndocumentation, which I need to talk about, and that is modularization and\ngenerating docs from docstrings.\nModular Documentation Okay so lets extend the index.rst file with another file. Lets say we have the\nfollowing folder structure\ndocs/ | -- index.rst | -- api.rst To include the extended documentation, we write the following in index.rst:\nDocumentation is Awesome! ========================= .. toctree:: :maxdepth: 1 :caption: Table of Contents: api This should include the api.rst file\nGenerating documentation from docstrings First we make sure we can include our python code by adding the following in\nour conf.py (fill out the path to the code):\n1  sys.path.insert(0, os.path.abspath(\u0026#39;\u0026lt;path to code\u0026gt;\u0026#39;))   and make sure the \u0026lsquo;sphinx.ext.autodoc\u0026rsquo; extention is added to extentions in\nconf.py. To write docstrings in a different format than traditional\nreStructuredText (such as numpy below), include the \u0026lsquo;sphinx.ext.napoleon\u0026rsquo; extention aswell.\nYou want to include your python module in your api.rst file, such as this:\nAPI documentaiton ================= .. automodule:: \u0026lt;my python module with docstrings\u0026gt; :members: Remember that it is included from the path set above.\nWrite docstrings in the code with, for example, the NumPy\nstyle docstrings, and finally compile the documentation with make.\n$ make html\nNow check out the docs, and you should see the docstrings in the documentation!\nReadTheDocs Deploying on ReadTheDocs is quite straight forward.\nJust set up a new account (with github), go to Dashboard\nand press \u0026ldquo;Import a Project\u0026rdquo;. Then select the repository with the sphinx\ndocumentation and you should be flying\nIf youve come this far, you can look at my test deployment here\nRound 2: Sphinx with gh-pages Since can be useful to deploy on gh-pages (such as in round 3), this next point will take on how we do that.\n Create a repository on github (which will be the gh-pages docs repo) Clone the repo as html:  $ git clone git@github.com/\u0026lt;username\u0026gt;/\u0026lt;repo\u0026gt;.git html  cd into the repo and run quickstart:  $ cd html \u0026amp;\u0026amp; sphinx-quickstart Make sure you select y youre being prompted about githubpages\n\u0026gt; githubpages: create .nojekyll file to publish the document on GitHub pages (y/n) [n]:  Now edit and build the docs. To run make clean (on html only), add the following to the makefile:  clean: @rm -rf $(BUILDDIR)/html/*.{html,js} $(BUILDDIR)/html/{objects.inv,_static,_sources,.buildinfo}  Add a few extra items to the .gitignore:  # User ignores objects.inv .buildinfo _sources  Commit and push the project with all the html compiled:  $ git commit -m \u0026quot;Added documentation as html for gh-pages\u0026quot; \u0026amp;\u0026amp; git push -u \u0026lt;repo\u0026gt;  Enable gh-pages on github for the repo by going to repository settings  Finally you should have it deployed on gh-pages like this,\nwith this repo\nRound 3: Sphinx with git submodules Adding submodules is pretty straight forward\n $ git submodule add \u0026lt;submodule\u0026gt; Add the docs in the submodule to the rst files Build and push the new documentation  Why do we do this? Well this is hugely useful if we have build our architecture\nusing microservices, and are not using a monorepo - which is common these\ndays. I wont go into details here - if you figured out Round 1 and 2 and know how git\nsubmodules work, then this should be a breeze.\nRound 4: Deploying docs with OAuth on Heroku And checking organization membership\nThis blogpost originally came from the desire to update and\nimprove the way my company does documentation. Understandably, they and many\nothers do not want all their trade secrets and proprietary technology openly\nexposed on the web, so I wanted to add a layer of protection on the\ndocumentation. Say hello to OAuth.\nNow Im not going to go into the depths of how OAuth works, as there are many\nguides already on that subject, and it can become a blogpost of its own.\nI want to just set up and deploy a layer of OAuth protection on the\ndocumentation. So for this I will planned the following:\n Use the Flask-Dance library\nto get OAuth capabilities Use GitHub OAuth Deploy on Heroku Check user organizations using OAuth and check if they are part of whatever\norg to authenticate  Cool, so lets get started!\nBuilding the application The author of the Flask Dance library had written an example implementation\nof Github OAuth, so I used it to get started. He also provided a very good\nreadme which I followed.\nTo check the organizations, I found an useful issue,\nand github api docs so I deployed the app with the following code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  import os import json from werkzeug.contrib.fixers import ProxyFix from flask import Flask, redirect, url_for from flask_dance.contrib.github import make_github_blueprint, github app = Flask(__name__) app.wsgi_app = ProxyFix(app.wsgi_app) app.secret_key = os.environ.get(\u0026#34;FLASK_SECRET_KEY\u0026#34;, \u0026#34;supersekrit\u0026#34;) app.config[\u0026#34;GITHUB_OAUTH_CLIENT_ID\u0026#34;] = os.environ.get(\u0026#34;GITHUB_OAUTH_CLIENT_ID\u0026#34;) app.config[\u0026#34;GITHUB_OAUTH_CLIENT_SECRET\u0026#34;] = os.environ.get(\u0026#34;GITHUB_OAUTH_CLIENT_SECRET\u0026#34;) github_bp = make_github_blueprint(scope=\u0026#39;read:org\u0026#39;) app.register_blueprint(github_bp, url_prefix=\u0026#34;/login\u0026#34;) AMEDIA_ORG_ID = 582844 @app.route(\u0026#34;/\u0026#34;) def index(): if not github.authorized: return redirect(url_for(\u0026#34;github.login\u0026#34;)) # Get user details resp = github.get(\u0026#34;/user\u0026#34;) ret = \u0026#39;\u0026lt;h2\u0026gt;USER DETAILS:\u0026lt;/h2\u0026gt;\u0026lt;br\u0026gt;\u0026#39; if resp.ok: ret += \u0026#34;You are %son GitHub\u0026lt;br\u0026gt;\u0026#34; % resp.json()[\u0026#34;login\u0026#34;] else: ret += \u0026#39;FAILED AT GETTING USER DATA\u0026lt;br\u0026gt;\u0026#39; # Get user organizations ret += \u0026#39;\u0026lt;h2\u0026gt;ORGANIZATIONS:\u0026lt;/h2\u0026gt;\u0026lt;br\u0026gt;\u0026#39; resp = github.get(\u0026#34;/user/orgs\u0026#34;) if not resp.ok: ret += \u0026#39;FAILED AT GETTING USERORG DATA\u0026lt;br\u0026gt;\u0026#39; else: u_orgs = resp.json() ret += \u0026#34;\u0026lt;pre\u0026gt;%s\u0026lt;/pre\u0026gt;\u0026lt;br\u0026gt;\u0026#34; % json.dumps(u_orgs, indent=4) # Check if user is part of Amedia for org in u_orgs: if org.get(\u0026#39;id\u0026#39;, None) == AMEDIA_ORG_ID: ret += \u0026#39;\u0026lt;h3\u0026gt;--- YOU ARE PART OF AMEDIA ORGANIZATION --- \u0026lt;/h3\u0026gt;\u0026#39; break else: ret += \u0026#39;\u0026lt;h3\u0026gt;--- YOU ARE NOT MEMBER OF AMEDIA --- \u0026lt;/h3\u0026gt;\u0026#39; # Finally return the retval return ret if __name__ == \u0026#34;__main__\u0026#34;: app.run()   Some comments on the code above:\n Make sure the OAuth scope is correct too see user orgs. Notice the line  1  github_bp = make_github_blueprint(scope=\u0026#39;read:org\u0026#39;)    Use env vars for the client_id and client_secret  1  os.environ.get(\u0026#39;\u0026lt;env var\u0026gt;\u0026#39;)    Commit and push to a gh repo  Deploying to Heroku Deploying to Heroku was a breeze once I got into the jazz. The guide on the gh\nrepo was very nice to follow, but the basic steps are as follows:\n Create an account Press New-\u0026gt;Create new app Name the app something fun Press Connect to github (assuming the app is pushed to your gh) Select the app Make sure you have a Procfile, runtime.txt, app.json and\nrequirements.txt in the repo  Procfile is one line and looks like this\nweb: gunicorn app:app --log-file=- runtime.txt tells heroku the python dist to use, for example is says: \u0026ldquo;python-3.7.0\u0026rdquo; app.json provides heroku with some application meta information   Create a github OAuth application, provide the ClientID and Client Secret to\nthe heroku app using env vars in the heroku console (under application settings) If done correctly, you should now see the app on your website. See my demo If the auth works, you should be able to just config the flask app to serve\nthe docs as a static directory. I havent done this in the demo, but its no big thing  Final words Hopefully you now see that documentation is a large endeavour and that it is\nworth doing right. If you have followed my instructions above, you should be\natleast a bit familiar with pretty decent documentation stack.\nThis post became quite long, but I hope you got something out of it. I know\nI did, exploring this topic has been a fun journey.\nBest regards from Anders\n"
},
{
	"uri": "https://blog.peakbreaker.com/tags/sphinx/",
	"title": "Sphinx",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/go/",
	"title": "go",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/categories/golang/",
	"title": "Golang",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/post/2018-09-07-golang-with-the-paal-gang/",
	"title": "Golang with the Pålgang",
	"tags": ["go", "software", "web"],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Just a short intro to the basics of golang with Pål\nThis is Pål (He is the normal looking one by the window)\nPål is the superhero developer keeping the Sensario backend operational.\nI have worked Pål on his right hand side since mid 2017 and have enjoyed every\nsecond of it. We have been getting coffee together nearly every day, spoken\nand learned about software engineering together and discovered the magic of Vim\nand Chad memes together.\nFrom alg0001 on reddit\nPål joined the Sensario company mid 2017 with the goal of building the backend of\nthe company so it could handle and process the incoming traffic from both our\nIoT sensor nodes with LTE (which I am programming), users and he has provided\ndevelopment services for the the engineering team. To do this, he has shown great\nmastery of Golang.\nSo join us in discovering this great programming language!\nMain characteristics of Golang  General purpose programming language Compiled languate w/ great compile time and performance Static types Strings, chars, pointers, mutant for loops Implicit interfaces, structs, maps, slices and arrays Made with concurrency in mind; Goroutines and channels Nice utilities: Defer, multiple returns  Whats in $GOPATH? Golang has an environment variable which determines the workspace of your go\nproject. Coming from a C and Python background, this system took a bit getting\nused to for me, and the Golang package system is something that stopped me from\ngetting too much into it in the start. Anyway, in the GOPATH you create the\nfollowing folders:\n src: source =\u0026gt; This is where we keep our projects pkg: Object files =\u0026gt; We dont usually touch this, its for the go toolchain bin: Binary files =\u0026gt; We dont usually touch this, its for the go toolchain  This creates a $GOPATH workflow:\n With golang we import from $GOPATH/src/\u0026hellip; Normal structure is this:\n$GOPATH/src/myProj/vendor/package protip: Use godep instead of $ go get to maintain better structure. I wont get to much into the use of this in this post Note: Go 1.11 introduces experimental support for projects outside $GOPATH.\nHavent looked too closely on this yet, but theres a wiki entry  Golang Syntax A few of my main takeaways/heads up from the basics of golang syntax\n When returning multiple values, either give all returns a declaration in function prototype, or none (just datatypes). Declaring return variables in function prototype will return them implicitly.  func split(sum int) (x, y int) { x = sum * 4 / 9 y = sum - x return } The above function will return x and y implicitly because they are declared as returns in the function prototype. Sweet!\n go fmt is the standard for golang formatting/convention: $ go fmt myfile.go Golang scope rules are very simple, everything between {} is a scope In switch case statements, break is implicit/default and to ignore a break one\nwrites the fallthrough keyword  v := 42 switch v { case 100: fmt.Println(100) fallthrough case 42: fmt.Println(42) fallthrough case 1: fmt.Println(1) fallthrough default: fmt.Println(\u0026quot;default\u0026quot;) } // Output: // 42 // 1 // default In C, for example, this is switched. By default the switch statement in C will\nfallthrough, and one writes break to break the switch statement. In Golang,\nthe break is implicit. Since one most often want to break the switch statment,\nthe golang syntax is pretty great!\n Exported variables, constants and functions from packages must start with a capital letter  import ( \u0026quot;fmt\u0026quot; \u0026quot;math\u0026quot; ) func main() { fmt.Println(math.pi) // doesn't work fmt.Println(math.Pi) // works } A great tut on this in A Tour of Go\nGolang datatypes  Basics  uints/ints floats string: always utf-8 char: called rune, utf-8 =\u0026gt; int32 under the hood    Arrays  Arrays are lists of values  // var myArray [\u0026lt;optional len\u0026gt;]\u0026lt;datatype\u0026gt;{\u0026lt;optional initializer\u0026gt;} // myArray := [\u0026lt;optional len\u0026gt;]\u0026lt;datatype\u0026gt;{\u0026lt;optional initializer\u0026gt;} myArray := [2]string{'hello', 'world'}  Array utils:  // Getting length in int len(myArray) // Looping over array for idx, val := range myArray {...} Slices  Slices are parts of an underlying array  // array := [\u0026lt;len\u0026gt;]\u0026lt;datatype\u0026gt;{\u0026lt;optional initializer\u0026gt;} // slice := array[\u0026lt;begin\u0026gt;:\u0026lt;end\u0026gt;] And theyre very nice to work with. Here are some slice utils:\nlen(slice) // length of slice cap(slice) // capacity of slice append(\u0026lt;slice\u0026gt;, \u0026lt;value\u0026gt;[, \u0026lt;more values\u0026gt;]) // returns a new slice Note on appending to slices: The new slice may point to the underlying array\nonly if appending to the slice didnt overflow the array. Pål made a nice demo\non this:\ns := make([]string, 1, 2) // Length 1. Cap 2 s[0] = \u0026quot;start\u0026quot; // Base slice s1 := append(s, \u0026quot;slice 1\u0026quot;) // Shared undelying array s2 := append(s, \u0026quot;slice 2\u0026quot;) // Shared undelying array s3 := append(s, \u0026quot;slice 3\u0026quot;, \u0026quot;needs more space!\u0026quot;) // Exceedes cap. Allocates a new array fmt.Printf(\u0026quot;Before mutating:\\ns:\\t%v\\ns1:\\t%v\\ns2:\\t%v\\ns3:\\t%v\\n\u0026quot;, s, s1, s2, s3) s[0] = \u0026quot;mutated\u0026quot; fmt.Printf(\u0026quot;After mutating:\\ns:\\t%v\\ns1:\\t%v\\ns2:\\t%v\\ns3:\\t%v\\n\u0026quot;, s, s1, s2, s3) Outputs:\nBefore mutating: s:\t[start] s1:\t[start slice 2] s2:\t[start slice 2] s3:\t[start slice 3 needs more space!] After mutating: s:\t[mutated] s1:\t[mutated slice 2] s2:\t[mutated slice 2] s3:\t[start slice 3 needs more space!] hyyyyyiiiiiinteresting\nMaps  Maps are like python dictionaries, but they are type sensitive Example usage:  // syntax // myMap := map[\u0026lt;key type\u0026gt;]\u0026lt;val type\u0026gt;\\ // {\u0026lt;opt key\u0026gt;: \u0026lt;opt value\u0026gt;} // Example map myMap := map[string]float64{\u0026quot;Key\u0026quot;: 33} // Getting myVar := myMap[\u0026quot;myKey\u0026quot;] // Setting myMap[\u0026quot;myKey\u0026quot;] = \u0026lt;myValue\u0026gt;  Looping over maps:  for \u0026lt;key\u0026gt;, \u0026lt;value\u0026gt; := range myMap {...} for \u0026lt;key\u0026gt; := range myMap {...} Working with datatypes Here comes some of the nice golang features into play. So far we've only\nlooked at the basic capabilities and mechanics of the language\nCustom types  Custom types is like typedef in C Syntax: type   Example: type Hours int Custom types can be compared to same custom type or underlying type, but cannot be compared with different custom even if they share the same underlying type  Methods But Go isn't object oriented?\n Methods are implicit methods on types. It is a function with a specific receiver argument, which tells which types implement the method func (t ) ()  {\u0026hellip;} Now  vars will implement the  method In Go it is common to write methods that gracefully handle being called with nil receiver For example:  func (v Vertex) Abs() float64 {...} /* (using) --\u0026gt; */ vert.Abs() Structs  In concept pretty much like structs in C -\u0026gt; structured data Convention to make all struct methods take either values or pointers as recv Declaring struct:   type MyStruct struct { myArg string }  Initializing struct:   myStruct := MyStruct{MyArg: \u0026quot;Hello World!\u0026quot;} myStruct := MyStruct{\u0026quot;Hello World\u0026quot;} // Does the same, but need order of args  Using struct:  Non cap members of struct are private Accessing struct members are the same for pointers and value based structs\n(unlike c): myStruct.MyArg    Interfaces  The interface type is a set of method signatures Interfaces are implemented implicitly, if a datatype has the methods to satisfy the interface, it automatically implements the interface Syntax for declaring interface:  type \u0026lt;MyInterface\u0026gt; interface {/*methods*/}\n Describing interfaces:  fmt.Printf(\u0026quot;(%v, %T)\\n\u0026quot;, i, i) // i is an interface This will show us that the interface is just a tuple of a value and datatype.\nThis is well illustrated in the Tour of Go example.\nSome interfaces: (\u0026lt;nil\u0026gt;, \u0026lt;nil\u0026gt;) (42, int) (hello, string)  a variable declared as an interface may be initialized with all types with the corresponding methods  Golang concurrency Golang is built with concurrency in mind, and thus has some cool features for\nbuilding stuff concurrently, namely Goroutines and channels\n Goroutines  A syntax for starting goroutines Syntax: go  Goroutines cant catch/handle returns, but can interact with channels (see\nbelow)   Channels  Allows us to do IPC Syntax:    // Making channel: channel := make(chan \u0026lt;type\u0026gt;) // Reading from channel: \u0026lt;-chan // Writing to channel: chan\u0026lt;- \u0026lt;value\u0026gt; Utilies worth mentioning  pprof for analyzing load reflect for inspecting stuff encoding and json for serializing structured data Reader/Writer interfaces which are quite common  Thanks for reading This is all for now, later I may dive deeper into some of the parts of Golang!\n"
},
{
	"uri": "https://blog.peakbreaker.com/tags/software/",
	"title": "software",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/web/",
	"title": "web",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/categories/linux/",
	"title": "Linux",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/linux/",
	"title": "linux",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/networking/",
	"title": "networking",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/post/2018-07-29-terminal-wifi-connect/",
	"title": "Stuck at Terminal Island",
	"tags": ["linux", "terminal", "networking"],
	"categories": [],
	"series": [],
	"description": "Saving lost penguins",
	"content": "Terminals are great Being good on the terminal gives you fine grained control over a system. It is\nthe hallmark skill and language of the system administrator, and even if you're not\na professional sysadmin, you still have manage a system of some sort and it would help you to be\nable to manage it efficiently. If you're into IT and technology in any way\nit should be obvious that obtaining linux skills is pretty much always a good investment.\nSo once in a while I am stuck at a terminal island for some reason. What is terminal island? Well all you have is a terminal, but you also have no network connection. There are no cables available, and it would be so very nice to connect to wifi\u0026hellip; from the terminal. This can happen if for example youre booting into a linux system on a usb stick on a laptop and you have no cabeled network, or you're at a public place and your wifi GUI app is malfunctioning (both have happened to me). This is a horrible situation, because you will have to google your way to wifi from your phone, and if you're not an expert on wifi, networking and linux system administration from before, then you're gonne have a bad time.\nThe web is flooded with high verbosity on this subject, which is expected because there are a handful of different wifi security standards (and your first search result will for some reason be on WEP, which is insecure and hardly used). Networking is a big subject, and can be quite hard to understand unless you have experience with both networking and the specific networking technology (like good luck with understanding the bluetooth stack in a resonable amount of time). And you don't care.. you just want to connect to the WiFi!\nI thought that knowing wifi connection from the terminal would be a useful feather in my SysAdmin hat, so at some point I decided to create a TL;DR guide on this in my notes (didn't find anything sufficient simple online), and I noticed it would be a decent blogpost, so I thought I'd share it!\nTL;DR Prerequisite These tools usually come standard with most linux distros\n wpa_supplicant net-tools  Getting Status  Interface status :  $ ifconfig / ip addr show\n WLAN status :  $ iw \u0026lt;wlan inerface\u0026gt; info\nEnable wlan interface  Up :  $ ifconfig \u0026lt;interface\u0026gt; up\nFind networks  Scan :  $ iwlist \u0026lt;interface\u0026gt; scan\nConnect  WEP :  $ iwconfig \u0026lt;interface\u0026gt; essid \u0026lt;network name\u0026gt; key s:\u0026lt;password\u0026gt; But if you/sysadmin have any sense, you're probably using some flavor of wpa\n WPA : Couple of steps  Connection config creation :    $ wpa_passphrase \u0026lt;ssid\u0026gt; \u0026gt; \u0026lt;configfile\u0026gt;.conf -\u0026gt; Next you will be prompted for network password\n Connect to network :  $ wpa_supplicant -B -i\u0026lt;interface\u0026gt; -c\u0026lt;config (from above cmd)\u0026gt; -D\u0026lt;type (wext or nl80211 usually works)\u0026gt;  Release DHCP leases :  $ dhclient -r\n Get new DHCP lease :  $ dhclient \u0026lt;interface\u0026gt;\nCommon issues / FAQ  After running wpa_supplicant, ioctl might throw an error saying \u0026ldquo;Invalid argument\u0026rdquo;. This can be ignored When running wpa_supplicant, a process will be started. If you have multiple processes running, then you will not be able to connect to network because of conflicts. Therefore make sure you killall wpa_supplicants before running a new one :\n$ killall wpa_supplicant I prepended all commands with $, however many of them might have to be run as root (#), so do that when that is needed.  "
},
{
	"uri": "https://blog.peakbreaker.com/tags/terminal/",
	"title": "terminal",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/flask/",
	"title": "flask",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/categories/web/",
	"title": "Web",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/post/2018-06-13-web-basics-1/",
	"title": "Web is pretty cool",
	"tags": ["python", "flask", "web"],
	"categories": [],
	"series": [],
	"description": "",
	"content": "You affect the world by what you browse.\n Tim Berners Lee, inventor of the web  Web is pretty cool The web is one of the main contributors to the internet revolution. If you've ever used a browser, or computer with an internet connection the last decade, you've probably used the web. Its quite useful and pretty cool, but how does it work? Let's take a look!\nWhy is the web pretty cool? Ever heard of the \u0026ldquo;.com bubble\u0026rdquo;? Yeah, it was basically a huge market crash in the late 90s because of the overhype of the internet. College kids were planning IPOs in their dorms, and investors threw money at anything with a website. It was the time where everyone could be an expert hacker by knowing XSS and basic code injection, or one could walk into a company saying \u0026ldquo;I know HTML tables\u0026rdquo; and get hired as a junior engineer on the spot. Good times indeed. Today? Not so much.\nWhy is this? Well today we hardly think about the value of the internet and web, because it has soaked itself into our everyday life, but back in the 90s things like mobile phones, computers and that you could order stuff online was friggin sci-fi level technology. And it is. We do not think about how amazing these technologies are today, but it is increasingly harder to imagine a world without webservices and magic websites which can serve you personalized and highly accurate data every day, or give you magical interaction with the world. The capabilities and the vision of the internet as the neural net connecting humanity as a single brain is scarily awesome. So\u0026hellip; stepping foot into web technology is today a bit more complex than before.\nSo fear not - We have Python.\nSo what do we even mean by web? At its core, the web is actually quite simple. The main point to understand about the web is that it is basically just a system for sharing documents, HTML documents that is, through the HTTP protocol. Thats right, if youre a webdeveloper, you work with one protocol. One. Well thats not entirely accurate - there are websockets, FTP, SSH, TLS, DB protocols and stuff - but for the most part you will work with HTTP. Oh, and Tim Berners Lee is credited as the inventor of HTTP, so he gets a quote at the top of this blogpost. Congrats Timmy!\nSo TL;DR on what web is: A system for sharing documents through the HTTP protocol.\nLets set up a webserver This is the best part of this blogpost\nThere is a million and more ways to implement a webserver, but due to the simplicity and readability of python and flask we will be using that to illustrate each part of the technology. So enter flask!\n![Python flask]({{ site.baseurl }}/assets/img/web/flask.png)\nFirst we install python, you can follow the instructions in this link\nand use the python packagemanager pip to install flask:\n$ pip install flask\n1 2 3 4 5 6 7 8 9  from flask import Flask app = Flask(__name__) @app.route(\u0026#34;/\u0026#34;) def hello(): return \u0026#34;Hello World!\u0026#34; if __name__ == \u0026#39;__main__\u0026#39;: app.run(debug=True, port=8000)   and run the program\n$ python hello.py\nThen go to http://localhost:8000 and you should see \u0026ldquo;Hello World\u0026rdquo;! Awesome!\nCongrats - You just set up your first webserver!\n"
},
{
	"uri": "https://blog.peakbreaker.com/post/2018-05-29-cooking-vr-with-ichih/",
	"title": "Cooking up VR with I-chih",
	"tags": ["VR", "OculusRift", "Unity3D"],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Just a heads up dear reader - My posts have two parts. The first part is a personal story and the second part is purely about technology and code\n\u0026ndash; If youre here just for code snippets, then scroll down \u0026ndash;\nThis is I-chih (she is the one to the left)\nShe is very concerned about the environment, and rightfully so - its an important issue. We first met back in 2017 at a clothe swapping party - back then it was after I opened a grocery store in Bergen, and I really needed some pants. We got along very well - she is always smiling and she is fun to work with. I like that in people. She is also taking her masters degree in visual communication here in Bergen, but before we get into that lets fast forward to January 2018.\nI attended Global Game Jam, which is a global 48h weekend session to create a game, with Kjetil, one of my friends from south Norway at the University of Agder where I took by bachelors. Together with him and Peer who we met there, we created a 2D platformer in Unity called Echo. Ill surely write a more detailed post at a later point about attending GGJ. Anyway, I-chih took note of that I wasn't completely useless in Unity3D and asked my help with her masters project, which concerned Unity3D with VR integration using Oculus Rift.\nUnity3D and VR? Awesome! I didn't own a VR headset and always wanted to see how its like making stuff for VR, so I said yes to help her out. Basically what I said yes to was to help her integrate her models and animations from Cinema4D - a 3D modeling and animation program - to Unity3D, write scripts to activate the animations whenever the player looked at the models, and to integrate Oculus Rift with the project aswell as letting the player teleport around the scenes to look around at the world.\nIt was actually quite fun, and here are the end results:\n  Code! Now I never intended to work much on Unity3D or blender or modelling or these kinds of things. I just happen to do it for fun. Even though my main work is about embedded systems, writing about 500 lines of code for device drivers can be very verbose for even seasoned engineers, while these kinds of VR, modelling and graphical things are fun to show off.\nAside from the digression, Ive gotten into a few things about how to integrate VR with unity projects. I was surprised at how simple it is to convert existing projects into VR in Unity3D, and indeed Unity3D is great at this - making it easy on the developers - looking aside from Unity's horrible sense of versioning: Unity comes with both semantic and rolling releases, whats that about? Oh yeah and the Version Control System (VCS) is pretty much a trainwreck (atleast at the time of writing this). I mean I don't know how much code Ive had to rewrite because of Unity's VCS, but its too much man.\nMy main takeaways from doing this project was the following:\n Using Oculus VR (OVR) Utilities Using the lovely animator controller Using the manager(-ish) pattern in Unity3D and keeping a tidy project  Lets look into each individually!\nUsing OVR Utilites To get started with using Oculus with Unity3D, one installs the OVR utilities. Indeed the guide (and documentation in general) from Unity is very good to follow. Download the utilities as a unitypackage here and import it to your project. Make sure your unity version is compatible with the OVR utilities.\nUsing Unity with Oculus touch controllers was pretty straight forward. Make sure the OVR Manager is in the scene and you should have access to the input methods.\nUsing OVR with UI was a bit of a challenge. The assignment was to be able to answer a quiz, built with Unity3Ds UI tools, in Oculus VR. To solve it, I followed this guide to the letter - a bit tricky. It worked but ..\nA quite frustrating issue we ran into when porting from normal UI on the screen to OVR was the player clicked a button to answer a quiz question. The next question would automatically be answered on the same spot that the previous question was answered. At first I thought this was due to the player holding the button down for too long or that the UI switched to the next question too fast. I applied a delay in order to wait for a second before showing the next question:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  // Added for the time delay public void Wait(float seconds, Action action) { StartCoroutine(_wait(seconds, action)); } IEnumerator _wait(float time, Action callback) { yield return new WaitForSeconds(time); callback(); } (...) // Call the 1 second wait Wait(1, () =\u0026gt; { ShowQuestion(); });    Note that in Unity3D you have to use coroutines in order to get time delays, since normal execution is (often) locked to frames (e.g. calling from void Update(){\u0026hellip;}).\nThis fix didn't work. After analyzing the issue closer, I still couldn't find the root cause. In order to not waste more time on the issue, I figured I would create a guard statement to check the time between answers - if the time was shorter than a few sec since last answer, then the following answer would be ignored. This worked great, the code was slick aswell, and had us moving forward in no time:\n1 2 3 4  // Guard statement to omit issue with question jumping if (Time.time - timeElapsedQuestion \u0026lt; 2.0f) return; timeElapsedQuestion = Time.time;    The animator components and Unity3D Animation stack To get animations working and to be able to alter them through the scripting system, unity provides the animator controller which is very slick for handling animations. Probably one of my favorite parts of the program. Even though code is itself very powerful for many things, sometimes using node editors can make the system much easier to represent and self documented. Since animation is indeed a very visual thing, node editors are often very useful for handling them - for example one of the most popular add-ons for blender is the node editor for animation handling.\nBasically the requirement was to activate the animations of animated objects after a short delay when the player looked at the objects. So I did the following:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  // In Start() we get all the animated objects by tag: // GameObject.FindGameObjectWithTag(\u0026#34;AnimObject\u0026#34;);  bool ObjectIsVisible(Vector3 targetPoint) { Camera MainCam = gameObject.GetComponent\u0026lt;CameraSwitcher\u0026gt;().MainCamera; Vector3 screenPoint = MainCam.WorldToViewportPoint(targetPoint); if (screenPoint.z \u0026gt; 0 \u0026amp;\u0026amp; screenPoint.x \u0026gt; 0 \u0026amp;\u0026amp; screenPoint.x \u0026lt; 1 \u0026amp;\u0026amp; screenPoint.y \u0026gt; 0 \u0026amp;\u0026amp; screenPoint.y \u0026lt; 1) return true; else return false; } // Update is called once per frame  void Update() { for (int i = 0; i \u0026lt; AnimObjects.Length; i++) // Loop through the objects  { /* Get the data on the object */ _animObject = AnimObjects[i]; _animController = _animObject.GetComponent\u0026lt;Animator\u0026gt;(); _curr_animAmount = _animController.GetFloat(\u0026#34;AnimParam\u0026#34;); if (ObjectIsVisible(_animObject.transform.GetChild(0).position)) { // If object is visible  _animController.SetFloat(\u0026#34;AnimParam\u0026#34;, ( _curr_animAmount \u0026lt; 5 ? _curr_animAmount + animationIncrementer : _curr_animAmount ) // Then increment animation  ); } else { // Object invisible  _animController.SetFloat(\u0026#34;AnimParam\u0026#34;, ( _curr_animAmount \u0026gt; 0 ? _curr_animAmount - animationIncrementer : _curr_animAmount ) // Then decrement animation  ); } } }    So in short this code will\n Iterate through all objects which we will be animating Check if the object is visible by player/main cam Increment the AnimParam float up to 5 every frame the player is looking at object If player is not looking at object, we will decrement the AnimParam  Unity3D Manager pattern There is a recurring pattern in Unity to have manager scripts to handle management of a scene, or at least as far as Ive seen (For example the OVR manager for Oculus). Basically this means that there are empty game objects in a scene which does not render or do anything purely visible, they just have scripts attached to them in order to handle various utility tasks. Atleast as far as Ive seen, this is a conventional way of building a unity project. The project tree may look something like this:\n | - (.. other gameobj ..) | - Levelmanager | - CameraManager | - etc These managers may also be nested under a top manager parent object. It gets obvious very soon that keeping a neat and refactored project in Unity and game development is super important!\nFor this project, part of the requirements was also to give the player the ability to \u0026ldquo;teleport\u0026rdquo; around the scene. This requirement was solved using this code in a manager object called CameraSwitcher:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  /* cameras is an array of Camera objects. We can get all cameras in the scene at start by calling the following code: cameras = Camera.allCameras; Next we can use the SetCameraActive function with an index to enable a given camera */ public void SetCameraActive(int _cameraIndex) { for (int i = 0; i \u0026lt; cameras.Length; i++) { cameras[i].gameObject.GetComponent\u0026lt;AudioListener\u0026gt;().enabled = false; cameras[i].enabled = false; } cameras[_cameraIndex].gameObject.GetComponent\u0026lt;AudioListener\u0026gt;().enabled = false; cameras[_cameraIndex].enabled = true; MainCamera = cameras[_cameraIndex]; Debug.Log(\u0026#34;Main camera is now\u0026#34; + MainCamera); }    Now basically what is does is go through a list of all the cameras in the scene, and once the SetCameraActive is called with a valid index, it will switch to that given camera. A neat little manager.\nThanks for reading Hope you enjoyed this blogpost on Unity3D with Oculus rift!\n Anders  "
},
{
	"uri": "https://blog.peakbreaker.com/tags/oculusrift/",
	"title": "OculusRift",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/unity3d/",
	"title": "Unity3D",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/vr/",
	"title": "VR",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/categories/xr/",
	"title": "XR",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/3d/",
	"title": "3d",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/categories/blender/",
	"title": "Blender",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/blender/",
	"title": "blender",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/post/2018-04-08-cgi-for-engineers-1/",
	"title": "CGI for Engineers Pt. 1",
	"tags": ["blender", "3d", "modelling"],
	"categories": [],
	"series": [],
	"description": "Overview, models and texturing",
	"content": "Blender is great Blender is an open source 3D computer graphics software for creating pretty much whatever you can imagine in 3D.\nIt is a pretty awesome piece of software, entirely free as in beer and speech, with a great amount of features for creating professional level content. In the hands of a trained person the results can be quite astonishing. Just take a look at this short film made by the blender foundation itself:\n  Thats cool, but.. Youre not going to be a professional 3D artist. Or if you are then this post is not meant for you. You're into engineering and making products and stuff, so why would you ever need CGI?\nWhy learn blender / CGI as an engineer? Engineers will find themselves making models using CAD software from time to time. Or design systems which requires a lot of learning for other people to comprehend. Your goal will always be to work with other people and sell forward your product, and therefore you must be able to show off your work. Knowing blender for 3d graphics together with inkscape for vectorgraphics and gimp for photoshop can give you a very powerful stack for displaying your work. Don't get me wrong though - blender is not CAD software.\nIn addition Blender is a fun and versatile software, and as an engineer your job is to be the king of tools. The job description of an engineer is someone who can create awesome stuff, and gripping the basics of CGI and blender will help pursuing this goal. Convinced? Great!\nInteresting, can we get our hands dirty now? Yes! Time for the fun part - Lets look at some super simple basics of blender!\nTo create a textured model there are basically 3 things we need to do:\n Create the mesh (modelling) Mapping our mesh and applying textures Adding our materials  Allright, lets try to make this low poly tombstone to just get a grip of the basics:\n[I just found it as a simple model to make to understand the basic principles]\nModel:  We can use the default cube when opening a new scene, or create a new cube by pressing Shift-A -\u0026gt; mesh -\u0026gt; cube To edit the cube object we enter edit mode by selecting the cube and pressing Tab At the lower part of the window you see this (see below) which will let you select vertex/edge/face  To make the model we select different vertecies/edges and faces and use G to move them about and S to scale the selections, and extrude new elements with E - You just have to try about things till you have what looks good. Finally you should have something that looks like this\n  Mapping, materials and texturing:  First we gotta UV map our model. If you dont know what this is, google it and read abit on the wiki page for the subject. The first part of this in blender is to mark seams. Select edges (in edit mode), hit CTRL-E and mark seam. Seams are where our unwrapper cannot stitch our UV map. After getting our seams correct we can unwrap our model. Select all vertecies/edges/faces on our model with A and hit U and -\u0026gt; Unwrap Bring up a pane with with UV/Image editor, add an image\n One would typically check and alter the UV map with a checkerpattern now, but we will skip this step in this tut We will now add our material. Make sure you are using cycles render as the rendering engine (set this in upper right corner), go to the materials tab (see below), and create a new material. On the material, make sure you are using nodes.\n Enter node editor, add a Image Texture node with SHIFT-A -\u0026gt; Texture -\u0026gt; Image Texture and put the output to a diffuse shader node which has its output to the Material output.\n We can now enter texture mode and start texturing our model!   Now make the model like you want it\nHope you enjoyed this tut, I know I did. See you later! :)\n"
},
{
	"uri": "https://blog.peakbreaker.com/tags/modelling/",
	"title": "modelling",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/blog/",
	"title": "blog",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/github/",
	"title": "github",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/post/2018-04-07-hello-jekyll/",
	"title": "Hello, Jekyll!",
	"tags": ["jekyll", "github", "blog"],
	"categories": [],
	"series": [],
	"description": "",
	"content": "Hello, world! Thought it was about time I set up a blog. For those who don't know me:\nI am Anders and I think engineering, technology and learning about interesting topics is a fun way to spend a saturday afternoon - especially if I can materialize that knowledge into something useful.\nI am not going to deny that I find battery technology and software design patterns as awesome topics of discussion, that I have at some point written a program to automate my use of Tinder, and that I find Vim keybindings in Emacs is the best thing ever. (Along with that last point I get a ton of heat from my coworkers for apparently living in the 80s because thats when Emacs comes from)\nI hope here to document my crazy adventure through technology as an engineer in the 21st century, so come along and join me!\n$ jekyll serve In order to deliver this fantastic content I am using jekyll on github pages.\nI figured, as a developers blog, that github pages would be a great place to serve my blog. With Jekyll and git I can easily keep track of my blog and update new posts as inspiration hits me.\nYay!\nAnd its really quite simple to use, and just in general makes writing a static blog site awesome.\nA great tool. The best. Fantastic.\nSo stay tuned, We'll see if I can keep to posting here at some pace.\n"
},
{
	"uri": "https://blog.peakbreaker.com/categories/jekyll/",
	"title": "Jekyll",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/tags/jekyll/",
	"title": "jekyll",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://blog.peakbreaker.com/series/",
	"title": "Series",
	"tags": [],
	"categories": [],
	"series": [],
	"description": "",
	"content": ""
}]